{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, let's import a few common modules, ensure MatplotLib plots figures inline. We also check that Python 3.5 or later is installed (although Python 2.x may work, it is deprecated so we strongly recommend you use Python 3 instead), as well as Scikit-Learn ≥0.20."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 708,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Python ≥3.5 is required\n",
    "import sys\n",
    "assert sys.version_info >= (3, 5)\n",
    "\n",
    "# Scikit-Learn ≥0.20 is required\n",
    "import sklearn\n",
    "assert sklearn.__version__ >= \"0.20\"\n",
    "\n",
    "# Common imports\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# to make this notebook's output stable across runs\n",
    "np.random.seed(42)\n",
    "\n",
    "# To plot pretty figures\n",
    "%matplotlib inline\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "mpl.rc('axes', labelsize=14)\n",
    "mpl.rc('xtick', labelsize=12)\n",
    "mpl.rc('ytick', labelsize=12)\n",
    "\n",
    "# ignore convergence warning for now\n",
    "import warnings\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "warnings.filterwarnings(\"ignore\", category=ConvergenceWarning,\n",
    "                            module=\"sklearn\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tackle the Titanic dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The goal is to predict whether or not a passenger survived based on attributes such as their age, sex, passenger class, where they embarked and so on."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, let's load the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 709,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "train_data = pd.read_csv(\"train.csv\")\n",
    "test_data = pd.read_csv(\"test.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data is already split into a training set and a test set. However, the test data does *not* contain the labels: your goal is to train the best model you can using the training data, then make your predictions on the test data and upload them to WTClass to see your score."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a peek at the top few rows of the training set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 710,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.head();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The attributes have the following meaning:\n",
    "* **Survived**: that's the target, 0 means the passenger did not survive, while 1 means he/she survived.\n",
    "* **Pclass**: passenger class.\n",
    "* **Name**, **Sex**, **Age**: self-explanatory\n",
    "* **SibSp**: how many siblings & spouses of the passenger aboard the Titanic.\n",
    "* **Parch**: how many children & parents of the passenger aboard the Titanic.\n",
    "* **Ticket**: ticket id\n",
    "* **Fare**: price paid (in pounds)\n",
    "* **Cabin**: passenger's cabin number\n",
    "* **Embarked**: where the passenger embarked the Titanic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's get more info to see how much data is missing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 711,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 712 entries, 0 to 711\n",
      "Data columns (total 12 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   PassengerId  712 non-null    int64  \n",
      " 1   Survived     712 non-null    int64  \n",
      " 2   Pclass       712 non-null    int64  \n",
      " 3   Name         712 non-null    object \n",
      " 4   Sex          712 non-null    object \n",
      " 5   Age          572 non-null    float64\n",
      " 6   SibSp        712 non-null    int64  \n",
      " 7   Parch        712 non-null    int64  \n",
      " 8   Ticket       712 non-null    object \n",
      " 9   Fare         712 non-null    float64\n",
      " 10  Cabin        159 non-null    object \n",
      " 11  Embarked     710 non-null    object \n",
      "dtypes: float64(2), int64(5), object(5)\n",
      "memory usage: 66.9+ KB\n"
     ]
    }
   ],
   "source": [
    "train_data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Okay, the **Age**, **Cabin** and **Embarked** attributes are sometimes null (less than 712 non-null), especially the **Cabin** (77% are null). We will ignore the **Cabin** for now and focus on the rest. The **Age** attribute has about 20% null values, so we will need to decide what to do with them. Replacing null values with the median age seems reasonable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The **Name** and **Ticket** attributes may have some value, but they will be a bit tricky to convert into useful numbers that a model can consume. So for now, we will ignore them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a look at the numerical attributes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 712,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.describe();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Yikes, only 37.6% **Survived**. :(  That's close enough to 40%, so **accuracy** will be a reasonable metric to evaluate our model.\n",
    "* The mean **Fare** was £32.60, which does not seem so expensive (but it was probably a lot of money back then).\n",
    "* The mean **Age** was less than 30 years old."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check that the target is indeed 0 or 1:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 713,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data[\"Survived\"].value_counts();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's take a quick look at all the categorical attributes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 714,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data[\"Pclass\"].value_counts();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 715,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data[\"Sex\"].value_counts();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 716,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data[\"Embarked\"].value_counts();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 717,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Anecia's solutions just to see\n",
    "train_data[\"Parch\"].value_counts();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 718,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Anecia's solutions just to see\n",
    "train_data[\"SibSp\"].value_counts();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 719,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>PassengerId</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.030183</td>\n",
       "      <td>0.005104</td>\n",
       "      <td>-0.003894</td>\n",
       "      <td>0.027698</td>\n",
       "      <td>-0.057984</td>\n",
       "      <td>-0.019042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Survived</th>\n",
       "      <td>-0.030183</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.321750</td>\n",
       "      <td>-0.059695</td>\n",
       "      <td>-0.047602</td>\n",
       "      <td>0.078311</td>\n",
       "      <td>0.246641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pclass</th>\n",
       "      <td>0.005104</td>\n",
       "      <td>-0.321750</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.355950</td>\n",
       "      <td>0.086933</td>\n",
       "      <td>0.012679</td>\n",
       "      <td>-0.546794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Age</th>\n",
       "      <td>-0.003894</td>\n",
       "      <td>-0.059695</td>\n",
       "      <td>-0.355950</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.320916</td>\n",
       "      <td>-0.207040</td>\n",
       "      <td>0.088103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SibSp</th>\n",
       "      <td>0.027698</td>\n",
       "      <td>-0.047602</td>\n",
       "      <td>0.086933</td>\n",
       "      <td>-0.320916</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.440355</td>\n",
       "      <td>0.153011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Parch</th>\n",
       "      <td>-0.057984</td>\n",
       "      <td>0.078311</td>\n",
       "      <td>0.012679</td>\n",
       "      <td>-0.207040</td>\n",
       "      <td>0.440355</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.222180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fare</th>\n",
       "      <td>-0.019042</td>\n",
       "      <td>0.246641</td>\n",
       "      <td>-0.546794</td>\n",
       "      <td>0.088103</td>\n",
       "      <td>0.153011</td>\n",
       "      <td>0.222180</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             PassengerId  Survived    Pclass       Age     SibSp     Parch  \\\n",
       "PassengerId     1.000000 -0.030183  0.005104 -0.003894  0.027698 -0.057984   \n",
       "Survived       -0.030183  1.000000 -0.321750 -0.059695 -0.047602  0.078311   \n",
       "Pclass          0.005104 -0.321750  1.000000 -0.355950  0.086933  0.012679   \n",
       "Age            -0.003894 -0.059695 -0.355950  1.000000 -0.320916 -0.207040   \n",
       "SibSp           0.027698 -0.047602  0.086933 -0.320916  1.000000  0.440355   \n",
       "Parch          -0.057984  0.078311  0.012679 -0.207040  0.440355  1.000000   \n",
       "Fare           -0.019042  0.246641 -0.546794  0.088103  0.153011  0.222180   \n",
       "\n",
       "                 Fare  \n",
       "PassengerId -0.019042  \n",
       "Survived     0.246641  \n",
       "Pclass      -0.546794  \n",
       "Age          0.088103  \n",
       "SibSp        0.153011  \n",
       "Parch        0.222180  \n",
       "Fare         1.000000  "
      ]
     },
     "execution_count": 719,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#I need to see the correlation to determine what categories are best to group together\n",
    "#PassengerId does not have much of a correlation and I will not be using it\n",
    "#Fare has a high correlation with survived\n",
    "#Fare has a noteable correlation with Sibsp and Parch\n",
    "#Fare has a high negative correlation with Pclass\n",
    "train_data.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 720,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data[\"AgeBucket\"] = train_data[\"Age\"] // 15 * 15\n",
    "train_data[[\"AgeBucket\", \"Survived\"]].groupby(['AgeBucket']).mean()\n",
    "train_data;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 721,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data[\"RelativesOnboard\"] = train_data[\"SibSp\"] + train_data[\"Parch\"]\n",
    "train_data[[\"RelativesOnboard\", \"Survived\"]].groupby(['RelativesOnboard']).mean()\n",
    "train_data;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 722,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "      <th>AgeBucket</th>\n",
       "      <th>RelativesOnboard</th>\n",
       "      <th>Title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Partner, Mr. Austen</td>\n",
       "      <td>male</td>\n",
       "      <td>45.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>113043</td>\n",
       "      <td>28.5000</td>\n",
       "      <td>C124</td>\n",
       "      <td>S</td>\n",
       "      <td>45.0</td>\n",
       "      <td>0</td>\n",
       "      <td>Mr.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>Berriman, Mr. William John</td>\n",
       "      <td>male</td>\n",
       "      <td>23.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>28425</td>\n",
       "      <td>13.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0</td>\n",
       "      <td>Mr.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Tikkanen, Mr. Juho</td>\n",
       "      <td>male</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O 2. 3101293</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0</td>\n",
       "      <td>Mr.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Hansen, Mr. Henrik Juul</td>\n",
       "      <td>male</td>\n",
       "      <td>26.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>350025</td>\n",
       "      <td>7.8542</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>15.0</td>\n",
       "      <td>1</td>\n",
       "      <td>Mr.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Andersson, Miss. Ebba Iris Alfrida</td>\n",
       "      <td>female</td>\n",
       "      <td>6.0</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>347082</td>\n",
       "      <td>31.2750</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6</td>\n",
       "      <td>Miss.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>707</th>\n",
       "      <td>708</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Salkjelsvik, Miss. Anna Kristine</td>\n",
       "      <td>female</td>\n",
       "      <td>21.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>343120</td>\n",
       "      <td>7.6500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0</td>\n",
       "      <td>Miss.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>708</th>\n",
       "      <td>709</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Cairns, Mr. Alexander</td>\n",
       "      <td>male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>113798</td>\n",
       "      <td>31.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>Mr.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>709</th>\n",
       "      <td>710</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Hansen, Mr. Claus Peter</td>\n",
       "      <td>male</td>\n",
       "      <td>41.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>350026</td>\n",
       "      <td>14.1083</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>30.0</td>\n",
       "      <td>2</td>\n",
       "      <td>Mr.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>710</th>\n",
       "      <td>711</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Carter, Miss. Lucile Polk</td>\n",
       "      <td>female</td>\n",
       "      <td>14.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>113760</td>\n",
       "      <td>120.0000</td>\n",
       "      <td>B96 B98</td>\n",
       "      <td>S</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>Miss.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>711</th>\n",
       "      <td>712</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>White, Mr. Richard Frasar</td>\n",
       "      <td>male</td>\n",
       "      <td>21.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>35281</td>\n",
       "      <td>77.2875</td>\n",
       "      <td>D26</td>\n",
       "      <td>S</td>\n",
       "      <td>15.0</td>\n",
       "      <td>1</td>\n",
       "      <td>Mr.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>712 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     PassengerId  Survived  Pclass                                Name  \\\n",
       "0              1         0       1                 Partner, Mr. Austen   \n",
       "1              2         0       2          Berriman, Mr. William John   \n",
       "2              3         0       3                  Tikkanen, Mr. Juho   \n",
       "3              4         0       3             Hansen, Mr. Henrik Juul   \n",
       "4              5         0       3  Andersson, Miss. Ebba Iris Alfrida   \n",
       "..           ...       ...     ...                                 ...   \n",
       "707          708         1       3    Salkjelsvik, Miss. Anna Kristine   \n",
       "708          709         0       1               Cairns, Mr. Alexander   \n",
       "709          710         0       3             Hansen, Mr. Claus Peter   \n",
       "710          711         1       1           Carter, Miss. Lucile Polk   \n",
       "711          712         0       1           White, Mr. Richard Frasar   \n",
       "\n",
       "        Sex   Age  SibSp  Parch             Ticket      Fare    Cabin  \\\n",
       "0      male  45.5      0      0             113043   28.5000     C124   \n",
       "1      male  23.0      0      0              28425   13.0000      NaN   \n",
       "2      male  32.0      0      0  STON/O 2. 3101293    7.9250      NaN   \n",
       "3      male  26.0      1      0             350025    7.8542      NaN   \n",
       "4    female   6.0      4      2             347082   31.2750      NaN   \n",
       "..      ...   ...    ...    ...                ...       ...      ...   \n",
       "707  female  21.0      0      0             343120    7.6500      NaN   \n",
       "708    male   NaN      0      0             113798   31.0000      NaN   \n",
       "709    male  41.0      2      0             350026   14.1083      NaN   \n",
       "710  female  14.0      1      2             113760  120.0000  B96 B98   \n",
       "711    male  21.0      0      1              35281   77.2875      D26   \n",
       "\n",
       "    Embarked  AgeBucket  RelativesOnboard  Title  \n",
       "0          S       45.0                 0    Mr.  \n",
       "1          S       15.0                 0    Mr.  \n",
       "2          S       30.0                 0    Mr.  \n",
       "3          S       15.0                 1    Mr.  \n",
       "4          S        0.0                 6  Miss.  \n",
       "..       ...        ...               ...    ...  \n",
       "707        S       15.0                 0  Miss.  \n",
       "708        S        NaN                 0    Mr.  \n",
       "709        S       30.0                 2    Mr.  \n",
       "710        S        0.0                 3  Miss.  \n",
       "711        S       15.0                 1    Mr.  \n",
       "\n",
       "[712 rows x 15 columns]"
      ]
     },
     "execution_count": 722,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Anecia's solutions\n",
    "#I created a new column called Title to separate the title of the person from their name\n",
    "train_data['Title']=train_data.Name.str.extract('\\, ([A-Z][^ ]*\\.)',expand=False)\n",
    "train_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 723,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Mr.        419\n",
       "Miss.      143\n",
       "Mrs.        96\n",
       "Master.     33\n",
       "Rev.         5\n",
       "Dr.          5\n",
       "Major.       2\n",
       "Col.         2\n",
       "Mlle.        2\n",
       "Capt.        1\n",
       "Mme.         1\n",
       "Ms.          1\n",
       "Lady.        1\n",
       "Name: Title, dtype: int64"
      ]
     },
     "execution_count": 723,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Anecia's solution\n",
    "#I need to see the different number of titles\n",
    "train_data[\"Title\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 724,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "      <th>AgeBucket</th>\n",
       "      <th>RelativesOnboard</th>\n",
       "      <th>Title</th>\n",
       "      <th>FancyN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Partner, Mr. Austen</td>\n",
       "      <td>male</td>\n",
       "      <td>45.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>113043</td>\n",
       "      <td>28.5000</td>\n",
       "      <td>C124</td>\n",
       "      <td>S</td>\n",
       "      <td>45.0</td>\n",
       "      <td>0</td>\n",
       "      <td>Mr.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>Berriman, Mr. William John</td>\n",
       "      <td>male</td>\n",
       "      <td>23.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>28425</td>\n",
       "      <td>13.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0</td>\n",
       "      <td>Mr.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Tikkanen, Mr. Juho</td>\n",
       "      <td>male</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O 2. 3101293</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0</td>\n",
       "      <td>Mr.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Hansen, Mr. Henrik Juul</td>\n",
       "      <td>male</td>\n",
       "      <td>26.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>350025</td>\n",
       "      <td>7.8542</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>15.0</td>\n",
       "      <td>1</td>\n",
       "      <td>Mr.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Andersson, Miss. Ebba Iris Alfrida</td>\n",
       "      <td>female</td>\n",
       "      <td>6.0</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>347082</td>\n",
       "      <td>31.2750</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6</td>\n",
       "      <td>Miss.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Baxter, Mr. Quigg Edmond</td>\n",
       "      <td>male</td>\n",
       "      <td>24.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>PC 17558</td>\n",
       "      <td>247.5208</td>\n",
       "      <td>B58 B60</td>\n",
       "      <td>C</td>\n",
       "      <td>15.0</td>\n",
       "      <td>1</td>\n",
       "      <td>Mr.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Butt, Major. Archibald Willingham</td>\n",
       "      <td>male</td>\n",
       "      <td>45.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>113050</td>\n",
       "      <td>26.5500</td>\n",
       "      <td>B38</td>\n",
       "      <td>S</td>\n",
       "      <td>45.0</td>\n",
       "      <td>0</td>\n",
       "      <td>Major.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>del Carlo, Mr. Sebastiano</td>\n",
       "      <td>male</td>\n",
       "      <td>29.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>SC/PARIS 2167</td>\n",
       "      <td>27.7208</td>\n",
       "      <td>NaN</td>\n",
       "      <td>C</td>\n",
       "      <td>15.0</td>\n",
       "      <td>1</td>\n",
       "      <td>Mr.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Todoroff, Mr. Lalio</td>\n",
       "      <td>male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>349216</td>\n",
       "      <td>7.8958</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>Mr.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Woolner, Mr. Hugh</td>\n",
       "      <td>male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>19947</td>\n",
       "      <td>35.5000</td>\n",
       "      <td>C52</td>\n",
       "      <td>S</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>Mr.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>Bystrom, Mrs. (Karolina)</td>\n",
       "      <td>female</td>\n",
       "      <td>42.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>236852</td>\n",
       "      <td>13.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0</td>\n",
       "      <td>Mrs.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Van Impe, Mr. Jean Baptiste</td>\n",
       "      <td>male</td>\n",
       "      <td>36.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>345773</td>\n",
       "      <td>24.1500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>30.0</td>\n",
       "      <td>2</td>\n",
       "      <td>Mr.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>Hunt, Mr. George Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>33.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>SCO/W 1585</td>\n",
       "      <td>12.2750</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0</td>\n",
       "      <td>Mr.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Jensen, Mr. Svend Lauritz</td>\n",
       "      <td>male</td>\n",
       "      <td>17.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>350048</td>\n",
       "      <td>7.0542</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>15.0</td>\n",
       "      <td>1</td>\n",
       "      <td>Mr.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Sheerlinck, Mr. Jan Baptist</td>\n",
       "      <td>male</td>\n",
       "      <td>29.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>345779</td>\n",
       "      <td>9.5000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0</td>\n",
       "      <td>Mr.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    PassengerId  Survived  Pclass                                Name     Sex  \\\n",
       "0             1         0       1                 Partner, Mr. Austen    male   \n",
       "1             2         0       2          Berriman, Mr. William John    male   \n",
       "2             3         0       3                  Tikkanen, Mr. Juho    male   \n",
       "3             4         0       3             Hansen, Mr. Henrik Juul    male   \n",
       "4             5         0       3  Andersson, Miss. Ebba Iris Alfrida  female   \n",
       "5             6         0       1            Baxter, Mr. Quigg Edmond    male   \n",
       "6             7         0       1   Butt, Major. Archibald Willingham    male   \n",
       "7             8         0       2           del Carlo, Mr. Sebastiano    male   \n",
       "8             9         0       3                 Todoroff, Mr. Lalio    male   \n",
       "9            10         1       1                   Woolner, Mr. Hugh    male   \n",
       "10           11         1       2            Bystrom, Mrs. (Karolina)  female   \n",
       "11           12         0       3         Van Impe, Mr. Jean Baptiste    male   \n",
       "12           13         0       2              Hunt, Mr. George Henry    male   \n",
       "13           14         0       3           Jensen, Mr. Svend Lauritz    male   \n",
       "14           15         1       3         Sheerlinck, Mr. Jan Baptist    male   \n",
       "\n",
       "     Age  SibSp  Parch             Ticket      Fare    Cabin Embarked  \\\n",
       "0   45.5      0      0             113043   28.5000     C124        S   \n",
       "1   23.0      0      0              28425   13.0000      NaN        S   \n",
       "2   32.0      0      0  STON/O 2. 3101293    7.9250      NaN        S   \n",
       "3   26.0      1      0             350025    7.8542      NaN        S   \n",
       "4    6.0      4      2             347082   31.2750      NaN        S   \n",
       "5   24.0      0      1           PC 17558  247.5208  B58 B60        C   \n",
       "6   45.0      0      0             113050   26.5500      B38        S   \n",
       "7   29.0      1      0      SC/PARIS 2167   27.7208      NaN        C   \n",
       "8    NaN      0      0             349216    7.8958      NaN        S   \n",
       "9    NaN      0      0              19947   35.5000      C52        S   \n",
       "10  42.0      0      0             236852   13.0000      NaN        S   \n",
       "11  36.0      1      1             345773   24.1500      NaN        S   \n",
       "12  33.0      0      0         SCO/W 1585   12.2750      NaN        S   \n",
       "13  17.0      1      0             350048    7.0542      NaN        S   \n",
       "14  29.0      0      0             345779    9.5000      NaN        S   \n",
       "\n",
       "    AgeBucket  RelativesOnboard   Title FancyN  \n",
       "0        45.0                 0     Mr.      0  \n",
       "1        15.0                 0     Mr.      0  \n",
       "2        30.0                 0     Mr.      0  \n",
       "3        15.0                 1     Mr.      0  \n",
       "4         0.0                 6   Miss.      0  \n",
       "5        15.0                 1     Mr.      0  \n",
       "6        45.0                 0  Major.      1  \n",
       "7        15.0                 1     Mr.      0  \n",
       "8         NaN                 0     Mr.      0  \n",
       "9         NaN                 0     Mr.      0  \n",
       "10       30.0                 0    Mrs.      0  \n",
       "11       30.0                 2     Mr.      0  \n",
       "12       30.0                 0     Mr.      0  \n",
       "13       15.0                 1     Mr.      0  \n",
       "14       15.0                 0     Mr.      0  "
      ]
     },
     "execution_count": 724,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Anecia's solutions\n",
    "#Dr.|Rev.|\n",
    "train_data['FancyN']=1*train_data['Title'].str.contains('Mlle.|Col.|Lady.|Sir.|Mme.|Capt.|Major.|Ms',regex=True)\n",
    "train_data.head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 725,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    701\n",
       "1     10\n",
       "Name: FancyN, dtype: int64"
      ]
     },
     "execution_count": 725,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[\"FancyN\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 726,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Mr.        419\n",
       "Miss.      143\n",
       "Mrs.        96\n",
       "Master.     33\n",
       "Rev.         5\n",
       "Dr.          5\n",
       "Major.       2\n",
       "Col.         2\n",
       "Mlle.        2\n",
       "Capt.        1\n",
       "Mme.         1\n",
       "Ms.          1\n",
       "Lady.        1\n",
       "Name: Title, dtype: int64"
      ]
     },
     "execution_count": 726,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Anecia's solution\n",
    "#Just to make sure I kept the title column the same\n",
    "train_data[\"Title\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 727,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Anecia's solution\n",
    "#Having done a correlation I decided to match these together\n",
    "train_data[\"RichS\"] = train_data[\"Sex\"] + train_data[\"Title\"] +train_data[\"Embarked\"]\n",
    "train_data[[\"RichS\", \"Survived\"]].groupby(['RichS']).mean()\n",
    "train_data;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 728,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Anecia's solution\n",
    "#I did this to add it with Age bucket\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "encoder = LabelEncoder()\n",
    "train_data['embarked_encoded'] = encoder.fit_transform(train_data.Embarked)\n",
    "train_data;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 729,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Anecia's solution\n",
    "train_data[\"Richie\"] = train_data[\"embarked_encoded\"] + train_data[\"AgeBucket\"] \n",
    "train_data[[\"Richie\", \"Survived\"]].groupby(['Richie']).mean()\n",
    "train_data;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 730,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Anecia's solution\n",
    "#There is defintely a correlation with age and Pclass. This will give me better results. Younger people in a higher class will have most likely survived.\n",
    "train_data[\"RichY\"] = train_data[\"Pclass\"] + train_data[\"Age\"] +train_data[\"FancyN\"]\n",
    "train_data[[\"RichY\", \"Survived\"]].groupby(['RichY']).mean()\n",
    "train_data;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 731,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Anecia's solution\n",
    "#Single people who paid a higher fare may be of higher status and will have most likely survived.\n",
    "train_data[\"UltraRich\"] = train_data[\"Fare\"] + train_data[\"RelativesOnboard\"] \n",
    "train_data[[\"UltraRich\", \"Survived\"]].groupby(['UltraRich']).mean()\n",
    "train_data;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 732,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Anecia's solution\n",
    "#I need sex to match with an integer/float category\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "encoder = LabelEncoder()\n",
    "train_data['sex_encoded'] = encoder.fit_transform(train_data.Sex)\n",
    "train_data;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 733,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>...</th>\n",
       "      <th>RelativesOnboard</th>\n",
       "      <th>Title</th>\n",
       "      <th>FancyN</th>\n",
       "      <th>RichS</th>\n",
       "      <th>embarked_encoded</th>\n",
       "      <th>Richie</th>\n",
       "      <th>RichY</th>\n",
       "      <th>UltraRich</th>\n",
       "      <th>sex_encoded</th>\n",
       "      <th>UC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Partner, Mr. Austen</td>\n",
       "      <td>male</td>\n",
       "      <td>45.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>113043</td>\n",
       "      <td>28.5000</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>Mr.</td>\n",
       "      <td>0</td>\n",
       "      <td>maleMr.S</td>\n",
       "      <td>2</td>\n",
       "      <td>47.0</td>\n",
       "      <td>46.5</td>\n",
       "      <td>28.5000</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>Berriman, Mr. William John</td>\n",
       "      <td>male</td>\n",
       "      <td>23.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>28425</td>\n",
       "      <td>13.0000</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>Mr.</td>\n",
       "      <td>0</td>\n",
       "      <td>maleMr.S</td>\n",
       "      <td>2</td>\n",
       "      <td>17.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>13.0000</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Tikkanen, Mr. Juho</td>\n",
       "      <td>male</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O 2. 3101293</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>Mr.</td>\n",
       "      <td>0</td>\n",
       "      <td>maleMr.S</td>\n",
       "      <td>2</td>\n",
       "      <td>32.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Hansen, Mr. Henrik Juul</td>\n",
       "      <td>male</td>\n",
       "      <td>26.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>350025</td>\n",
       "      <td>7.8542</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>Mr.</td>\n",
       "      <td>0</td>\n",
       "      <td>maleMr.S</td>\n",
       "      <td>2</td>\n",
       "      <td>17.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>8.8542</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Andersson, Miss. Ebba Iris Alfrida</td>\n",
       "      <td>female</td>\n",
       "      <td>6.0</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>347082</td>\n",
       "      <td>31.2750</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td>Miss.</td>\n",
       "      <td>0</td>\n",
       "      <td>femaleMiss.S</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>37.2750</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>707</th>\n",
       "      <td>708</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Salkjelsvik, Miss. Anna Kristine</td>\n",
       "      <td>female</td>\n",
       "      <td>21.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>343120</td>\n",
       "      <td>7.6500</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>Miss.</td>\n",
       "      <td>0</td>\n",
       "      <td>femaleMiss.S</td>\n",
       "      <td>2</td>\n",
       "      <td>17.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>7.6500</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>708</th>\n",
       "      <td>709</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Cairns, Mr. Alexander</td>\n",
       "      <td>male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>113798</td>\n",
       "      <td>31.0000</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>Mr.</td>\n",
       "      <td>0</td>\n",
       "      <td>maleMr.S</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>31.0000</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>709</th>\n",
       "      <td>710</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Hansen, Mr. Claus Peter</td>\n",
       "      <td>male</td>\n",
       "      <td>41.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>350026</td>\n",
       "      <td>14.1083</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>Mr.</td>\n",
       "      <td>0</td>\n",
       "      <td>maleMr.S</td>\n",
       "      <td>2</td>\n",
       "      <td>32.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>16.1083</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>710</th>\n",
       "      <td>711</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Carter, Miss. Lucile Polk</td>\n",
       "      <td>female</td>\n",
       "      <td>14.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>113760</td>\n",
       "      <td>120.0000</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>Miss.</td>\n",
       "      <td>0</td>\n",
       "      <td>femaleMiss.S</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>123.0000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>711</th>\n",
       "      <td>712</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>White, Mr. Richard Frasar</td>\n",
       "      <td>male</td>\n",
       "      <td>21.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>35281</td>\n",
       "      <td>77.2875</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>Mr.</td>\n",
       "      <td>0</td>\n",
       "      <td>maleMr.S</td>\n",
       "      <td>2</td>\n",
       "      <td>17.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>78.2875</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>712 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     PassengerId  Survived  Pclass                                Name  \\\n",
       "0              1         0       1                 Partner, Mr. Austen   \n",
       "1              2         0       2          Berriman, Mr. William John   \n",
       "2              3         0       3                  Tikkanen, Mr. Juho   \n",
       "3              4         0       3             Hansen, Mr. Henrik Juul   \n",
       "4              5         0       3  Andersson, Miss. Ebba Iris Alfrida   \n",
       "..           ...       ...     ...                                 ...   \n",
       "707          708         1       3    Salkjelsvik, Miss. Anna Kristine   \n",
       "708          709         0       1               Cairns, Mr. Alexander   \n",
       "709          710         0       3             Hansen, Mr. Claus Peter   \n",
       "710          711         1       1           Carter, Miss. Lucile Polk   \n",
       "711          712         0       1           White, Mr. Richard Frasar   \n",
       "\n",
       "        Sex   Age  SibSp  Parch             Ticket      Fare  ...  \\\n",
       "0      male  45.5      0      0             113043   28.5000  ...   \n",
       "1      male  23.0      0      0              28425   13.0000  ...   \n",
       "2      male  32.0      0      0  STON/O 2. 3101293    7.9250  ...   \n",
       "3      male  26.0      1      0             350025    7.8542  ...   \n",
       "4    female   6.0      4      2             347082   31.2750  ...   \n",
       "..      ...   ...    ...    ...                ...       ...  ...   \n",
       "707  female  21.0      0      0             343120    7.6500  ...   \n",
       "708    male   NaN      0      0             113798   31.0000  ...   \n",
       "709    male  41.0      2      0             350026   14.1083  ...   \n",
       "710  female  14.0      1      2             113760  120.0000  ...   \n",
       "711    male  21.0      0      1              35281   77.2875  ...   \n",
       "\n",
       "    RelativesOnboard  Title  FancyN         RichS embarked_encoded Richie  \\\n",
       "0                  0    Mr.       0      maleMr.S                2   47.0   \n",
       "1                  0    Mr.       0      maleMr.S                2   17.0   \n",
       "2                  0    Mr.       0      maleMr.S                2   32.0   \n",
       "3                  1    Mr.       0      maleMr.S                2   17.0   \n",
       "4                  6  Miss.       0  femaleMiss.S                2    2.0   \n",
       "..               ...    ...     ...           ...              ...    ...   \n",
       "707                0  Miss.       0  femaleMiss.S                2   17.0   \n",
       "708                0    Mr.       0      maleMr.S                2    NaN   \n",
       "709                2    Mr.       0      maleMr.S                2   32.0   \n",
       "710                3  Miss.       0  femaleMiss.S                2    2.0   \n",
       "711                1    Mr.       0      maleMr.S                2   17.0   \n",
       "\n",
       "    RichY  UltraRich  sex_encoded UC  \n",
       "0    46.5    28.5000            1  2  \n",
       "1    25.0    13.0000            1  3  \n",
       "2    35.0     7.9250            1  4  \n",
       "3    29.0     8.8542            1  4  \n",
       "4     9.0    37.2750            0  3  \n",
       "..    ...        ...          ... ..  \n",
       "707  24.0     7.6500            0  3  \n",
       "708   NaN    31.0000            1  2  \n",
       "709  44.0    16.1083            1  4  \n",
       "710  15.0   123.0000            0  1  \n",
       "711  22.0    78.2875            1  2  \n",
       "\n",
       "[712 rows x 23 columns]"
      ]
     },
     "execution_count": 733,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Anecia's solution\n",
    "#Females in higher class will have most likely survived.\n",
    "train_data[\"UC\"] = train_data[\"sex_encoded\"] + train_data[\"Pclass\"] \n",
    "train_data[[\"UC\", \"Survived\"]].groupby(['UC']).mean()\n",
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 734,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>...</th>\n",
       "      <th>Title</th>\n",
       "      <th>FancyN</th>\n",
       "      <th>RichS</th>\n",
       "      <th>embarked_encoded</th>\n",
       "      <th>Richie</th>\n",
       "      <th>RichY</th>\n",
       "      <th>UltraRich</th>\n",
       "      <th>sex_encoded</th>\n",
       "      <th>UC</th>\n",
       "      <th>Plclass</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Partner, Mr. Austen</td>\n",
       "      <td>male</td>\n",
       "      <td>45.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>113043</td>\n",
       "      <td>28.5000</td>\n",
       "      <td>...</td>\n",
       "      <td>Mr.</td>\n",
       "      <td>0</td>\n",
       "      <td>maleMr.S</td>\n",
       "      <td>2</td>\n",
       "      <td>47.0</td>\n",
       "      <td>46.5</td>\n",
       "      <td>28.5000</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>Berriman, Mr. William John</td>\n",
       "      <td>male</td>\n",
       "      <td>23.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>28425</td>\n",
       "      <td>13.0000</td>\n",
       "      <td>...</td>\n",
       "      <td>Mr.</td>\n",
       "      <td>0</td>\n",
       "      <td>maleMr.S</td>\n",
       "      <td>2</td>\n",
       "      <td>17.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>13.0000</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Tikkanen, Mr. Juho</td>\n",
       "      <td>male</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O 2. 3101293</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>...</td>\n",
       "      <td>Mr.</td>\n",
       "      <td>0</td>\n",
       "      <td>maleMr.S</td>\n",
       "      <td>2</td>\n",
       "      <td>32.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Hansen, Mr. Henrik Juul</td>\n",
       "      <td>male</td>\n",
       "      <td>26.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>350025</td>\n",
       "      <td>7.8542</td>\n",
       "      <td>...</td>\n",
       "      <td>Mr.</td>\n",
       "      <td>0</td>\n",
       "      <td>maleMr.S</td>\n",
       "      <td>2</td>\n",
       "      <td>17.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>8.8542</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Andersson, Miss. Ebba Iris Alfrida</td>\n",
       "      <td>female</td>\n",
       "      <td>6.0</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>347082</td>\n",
       "      <td>31.2750</td>\n",
       "      <td>...</td>\n",
       "      <td>Miss.</td>\n",
       "      <td>0</td>\n",
       "      <td>femaleMiss.S</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>37.2750</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>707</th>\n",
       "      <td>708</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Salkjelsvik, Miss. Anna Kristine</td>\n",
       "      <td>female</td>\n",
       "      <td>21.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>343120</td>\n",
       "      <td>7.6500</td>\n",
       "      <td>...</td>\n",
       "      <td>Miss.</td>\n",
       "      <td>0</td>\n",
       "      <td>femaleMiss.S</td>\n",
       "      <td>2</td>\n",
       "      <td>17.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>7.6500</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>708</th>\n",
       "      <td>709</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Cairns, Mr. Alexander</td>\n",
       "      <td>male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>113798</td>\n",
       "      <td>31.0000</td>\n",
       "      <td>...</td>\n",
       "      <td>Mr.</td>\n",
       "      <td>0</td>\n",
       "      <td>maleMr.S</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>31.0000</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>709</th>\n",
       "      <td>710</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Hansen, Mr. Claus Peter</td>\n",
       "      <td>male</td>\n",
       "      <td>41.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>350026</td>\n",
       "      <td>14.1083</td>\n",
       "      <td>...</td>\n",
       "      <td>Mr.</td>\n",
       "      <td>0</td>\n",
       "      <td>maleMr.S</td>\n",
       "      <td>2</td>\n",
       "      <td>32.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>16.1083</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>710</th>\n",
       "      <td>711</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Carter, Miss. Lucile Polk</td>\n",
       "      <td>female</td>\n",
       "      <td>14.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>113760</td>\n",
       "      <td>120.0000</td>\n",
       "      <td>...</td>\n",
       "      <td>Miss.</td>\n",
       "      <td>0</td>\n",
       "      <td>femaleMiss.S</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>123.0000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>711</th>\n",
       "      <td>712</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>White, Mr. Richard Frasar</td>\n",
       "      <td>male</td>\n",
       "      <td>21.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>35281</td>\n",
       "      <td>77.2875</td>\n",
       "      <td>...</td>\n",
       "      <td>Mr.</td>\n",
       "      <td>0</td>\n",
       "      <td>maleMr.S</td>\n",
       "      <td>2</td>\n",
       "      <td>17.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>78.2875</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>712 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     PassengerId  Survived  Pclass                                Name  \\\n",
       "0              1         0       1                 Partner, Mr. Austen   \n",
       "1              2         0       2          Berriman, Mr. William John   \n",
       "2              3         0       3                  Tikkanen, Mr. Juho   \n",
       "3              4         0       3             Hansen, Mr. Henrik Juul   \n",
       "4              5         0       3  Andersson, Miss. Ebba Iris Alfrida   \n",
       "..           ...       ...     ...                                 ...   \n",
       "707          708         1       3    Salkjelsvik, Miss. Anna Kristine   \n",
       "708          709         0       1               Cairns, Mr. Alexander   \n",
       "709          710         0       3             Hansen, Mr. Claus Peter   \n",
       "710          711         1       1           Carter, Miss. Lucile Polk   \n",
       "711          712         0       1           White, Mr. Richard Frasar   \n",
       "\n",
       "        Sex   Age  SibSp  Parch             Ticket      Fare  ...  Title  \\\n",
       "0      male  45.5      0      0             113043   28.5000  ...    Mr.   \n",
       "1      male  23.0      0      0              28425   13.0000  ...    Mr.   \n",
       "2      male  32.0      0      0  STON/O 2. 3101293    7.9250  ...    Mr.   \n",
       "3      male  26.0      1      0             350025    7.8542  ...    Mr.   \n",
       "4    female   6.0      4      2             347082   31.2750  ...  Miss.   \n",
       "..      ...   ...    ...    ...                ...       ...  ...    ...   \n",
       "707  female  21.0      0      0             343120    7.6500  ...  Miss.   \n",
       "708    male   NaN      0      0             113798   31.0000  ...    Mr.   \n",
       "709    male  41.0      2      0             350026   14.1083  ...    Mr.   \n",
       "710  female  14.0      1      2             113760  120.0000  ...  Miss.   \n",
       "711    male  21.0      0      1              35281   77.2875  ...    Mr.   \n",
       "\n",
       "    FancyN         RichS  embarked_encoded Richie RichY UltraRich  \\\n",
       "0        0      maleMr.S                 2   47.0  46.5   28.5000   \n",
       "1        0      maleMr.S                 2   17.0  25.0   13.0000   \n",
       "2        0      maleMr.S                 2   32.0  35.0    7.9250   \n",
       "3        0      maleMr.S                 2   17.0  29.0    8.8542   \n",
       "4        0  femaleMiss.S                 2    2.0   9.0   37.2750   \n",
       "..     ...           ...               ...    ...   ...       ...   \n",
       "707      0  femaleMiss.S                 2   17.0  24.0    7.6500   \n",
       "708      0      maleMr.S                 2    NaN   NaN   31.0000   \n",
       "709      0      maleMr.S                 2   32.0  44.0   16.1083   \n",
       "710      0  femaleMiss.S                 2    2.0  15.0  123.0000   \n",
       "711      0      maleMr.S                 2   17.0  22.0   78.2875   \n",
       "\n",
       "     sex_encoded  UC Plclass  \n",
       "0              1   2       3  \n",
       "1              1   3       4  \n",
       "2              1   4       5  \n",
       "3              1   4       5  \n",
       "4              0   3       5  \n",
       "..           ...  ..     ...  \n",
       "707            0   3       5  \n",
       "708            1   2       3  \n",
       "709            1   4       5  \n",
       "710            0   1       3  \n",
       "711            1   2       3  \n",
       "\n",
       "[712 rows x 24 columns]"
      ]
     },
     "execution_count": 734,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[\"Plclass\"] = train_data[\"embarked_encoded\"] + train_data[\"Pclass\"]\n",
    "train_data[[\"Plclass\", \"Survived\"]].groupby(['Plclass']).mean()\n",
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 735,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8.0500     35\n",
       "13.0000    33\n",
       "7.8958     32\n",
       "7.7500     26\n",
       "26.0000    25\n",
       "           ..\n",
       "40.1250     1\n",
       "15.1000     1\n",
       "61.1750     1\n",
       "59.4000     1\n",
       "14.1083     1\n",
       "Name: Fare, Length: 220, dtype: int64"
      ]
     },
     "execution_count": 735,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Anecia's solutions just to see\n",
    "train_data[\"Fare\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 736,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>AgeBucket</th>\n",
       "      <th>RelativesOnboard</th>\n",
       "      <th>embarked_encoded</th>\n",
       "      <th>Richie</th>\n",
       "      <th>UltraRich</th>\n",
       "      <th>sex_encoded</th>\n",
       "      <th>UC</th>\n",
       "      <th>Plclass</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>PassengerId</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.030183</td>\n",
       "      <td>0.005104</td>\n",
       "      <td>-0.003894</td>\n",
       "      <td>0.027698</td>\n",
       "      <td>-0.057984</td>\n",
       "      <td>-0.019042</td>\n",
       "      <td>0.007289</td>\n",
       "      <td>-0.007917</td>\n",
       "      <td>0.030591</td>\n",
       "      <td>0.008519</td>\n",
       "      <td>-0.019158</td>\n",
       "      <td>0.018778</td>\n",
       "      <td>0.013091</td>\n",
       "      <td>0.023285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Survived</th>\n",
       "      <td>-0.030183</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.321750</td>\n",
       "      <td>-0.059695</td>\n",
       "      <td>-0.047602</td>\n",
       "      <td>0.078311</td>\n",
       "      <td>0.246641</td>\n",
       "      <td>-0.047526</td>\n",
       "      <td>0.003565</td>\n",
       "      <td>-0.149680</td>\n",
       "      <td>-0.056505</td>\n",
       "      <td>0.244957</td>\n",
       "      <td>-0.541750</td>\n",
       "      <td>-0.521085</td>\n",
       "      <td>-0.317695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pclass</th>\n",
       "      <td>0.005104</td>\n",
       "      <td>-0.321750</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.355950</td>\n",
       "      <td>0.086933</td>\n",
       "      <td>0.012679</td>\n",
       "      <td>-0.546794</td>\n",
       "      <td>-0.361229</td>\n",
       "      <td>0.066748</td>\n",
       "      <td>0.124445</td>\n",
       "      <td>-0.349582</td>\n",
       "      <td>-0.540662</td>\n",
       "      <td>0.128672</td>\n",
       "      <td>0.882745</td>\n",
       "      <td>0.767058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Age</th>\n",
       "      <td>-0.003894</td>\n",
       "      <td>-0.059695</td>\n",
       "      <td>-0.355950</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.320916</td>\n",
       "      <td>-0.207040</td>\n",
       "      <td>0.088103</td>\n",
       "      <td>0.957010</td>\n",
       "      <td>-0.319651</td>\n",
       "      <td>0.015986</td>\n",
       "      <td>0.955440</td>\n",
       "      <td>0.079059</td>\n",
       "      <td>0.091598</td>\n",
       "      <td>-0.245294</td>\n",
       "      <td>-0.229125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SibSp</th>\n",
       "      <td>0.027698</td>\n",
       "      <td>-0.047602</td>\n",
       "      <td>0.086933</td>\n",
       "      <td>-0.320916</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.440355</td>\n",
       "      <td>0.153011</td>\n",
       "      <td>-0.305981</td>\n",
       "      <td>0.906387</td>\n",
       "      <td>0.079193</td>\n",
       "      <td>-0.303413</td>\n",
       "      <td>0.181026</td>\n",
       "      <td>-0.104174</td>\n",
       "      <td>0.022083</td>\n",
       "      <td>0.110894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Parch</th>\n",
       "      <td>-0.057984</td>\n",
       "      <td>0.078311</td>\n",
       "      <td>0.012679</td>\n",
       "      <td>-0.207040</td>\n",
       "      <td>0.440355</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.222180</td>\n",
       "      <td>-0.206335</td>\n",
       "      <td>0.778416</td>\n",
       "      <td>0.049868</td>\n",
       "      <td>-0.204779</td>\n",
       "      <td>0.245578</td>\n",
       "      <td>-0.250724</td>\n",
       "      <td>-0.108371</td>\n",
       "      <td>0.040950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fare</th>\n",
       "      <td>-0.019042</td>\n",
       "      <td>0.246641</td>\n",
       "      <td>-0.546794</td>\n",
       "      <td>0.088103</td>\n",
       "      <td>0.153011</td>\n",
       "      <td>0.222180</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.089143</td>\n",
       "      <td>0.211525</td>\n",
       "      <td>-0.203755</td>\n",
       "      <td>0.075011</td>\n",
       "      <td>0.999507</td>\n",
       "      <td>-0.171665</td>\n",
       "      <td>-0.530678</td>\n",
       "      <td>-0.507173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AgeBucket</th>\n",
       "      <td>0.007289</td>\n",
       "      <td>-0.047526</td>\n",
       "      <td>-0.361229</td>\n",
       "      <td>0.957010</td>\n",
       "      <td>-0.305981</td>\n",
       "      <td>-0.206335</td>\n",
       "      <td>0.089143</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.309688</td>\n",
       "      <td>0.021881</td>\n",
       "      <td>0.998631</td>\n",
       "      <td>0.080361</td>\n",
       "      <td>0.091919</td>\n",
       "      <td>-0.249418</td>\n",
       "      <td>-0.229037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RelativesOnboard</th>\n",
       "      <td>-0.007917</td>\n",
       "      <td>0.003565</td>\n",
       "      <td>0.066748</td>\n",
       "      <td>-0.319651</td>\n",
       "      <td>0.906387</td>\n",
       "      <td>0.778416</td>\n",
       "      <td>0.211525</td>\n",
       "      <td>-0.309688</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.078835</td>\n",
       "      <td>-0.307185</td>\n",
       "      <td>0.242122</td>\n",
       "      <td>-0.190809</td>\n",
       "      <td>-0.035551</td>\n",
       "      <td>0.096804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>embarked_encoded</th>\n",
       "      <td>0.030591</td>\n",
       "      <td>-0.149680</td>\n",
       "      <td>0.124445</td>\n",
       "      <td>0.015986</td>\n",
       "      <td>0.079193</td>\n",
       "      <td>0.049868</td>\n",
       "      <td>-0.203755</td>\n",
       "      <td>0.021881</td>\n",
       "      <td>0.078835</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.074150</td>\n",
       "      <td>-0.199735</td>\n",
       "      <td>0.080068</td>\n",
       "      <td>0.140202</td>\n",
       "      <td>0.732046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Richie</th>\n",
       "      <td>0.008519</td>\n",
       "      <td>-0.056505</td>\n",
       "      <td>-0.349582</td>\n",
       "      <td>0.955440</td>\n",
       "      <td>-0.303413</td>\n",
       "      <td>-0.204779</td>\n",
       "      <td>0.075011</td>\n",
       "      <td>0.998631</td>\n",
       "      <td>-0.307185</td>\n",
       "      <td>0.074150</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.066373</td>\n",
       "      <td>0.096075</td>\n",
       "      <td>-0.238039</td>\n",
       "      <td>-0.189018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>UltraRich</th>\n",
       "      <td>-0.019158</td>\n",
       "      <td>0.244957</td>\n",
       "      <td>-0.540662</td>\n",
       "      <td>0.079059</td>\n",
       "      <td>0.181026</td>\n",
       "      <td>0.245578</td>\n",
       "      <td>0.999507</td>\n",
       "      <td>0.080361</td>\n",
       "      <td>0.242122</td>\n",
       "      <td>-0.199735</td>\n",
       "      <td>0.066373</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.176546</td>\n",
       "      <td>-0.527951</td>\n",
       "      <td>-0.500364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sex_encoded</th>\n",
       "      <td>0.018778</td>\n",
       "      <td>-0.541750</td>\n",
       "      <td>0.128672</td>\n",
       "      <td>0.091598</td>\n",
       "      <td>-0.104174</td>\n",
       "      <td>-0.250724</td>\n",
       "      <td>-0.171665</td>\n",
       "      <td>0.091919</td>\n",
       "      <td>-0.190809</td>\n",
       "      <td>0.080068</td>\n",
       "      <td>0.096075</td>\n",
       "      <td>-0.176546</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.579532</td>\n",
       "      <td>0.140117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>UC</th>\n",
       "      <td>0.013091</td>\n",
       "      <td>-0.521085</td>\n",
       "      <td>0.882745</td>\n",
       "      <td>-0.245294</td>\n",
       "      <td>0.022083</td>\n",
       "      <td>-0.108371</td>\n",
       "      <td>-0.530678</td>\n",
       "      <td>-0.249418</td>\n",
       "      <td>-0.035551</td>\n",
       "      <td>0.140202</td>\n",
       "      <td>-0.238039</td>\n",
       "      <td>-0.527951</td>\n",
       "      <td>0.579532</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.696740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Plclass</th>\n",
       "      <td>0.023285</td>\n",
       "      <td>-0.317695</td>\n",
       "      <td>0.767058</td>\n",
       "      <td>-0.229125</td>\n",
       "      <td>0.110894</td>\n",
       "      <td>0.040950</td>\n",
       "      <td>-0.507173</td>\n",
       "      <td>-0.229037</td>\n",
       "      <td>0.096804</td>\n",
       "      <td>0.732046</td>\n",
       "      <td>-0.189018</td>\n",
       "      <td>-0.500364</td>\n",
       "      <td>0.140117</td>\n",
       "      <td>0.696740</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  PassengerId  Survived    Pclass       Age     SibSp  \\\n",
       "PassengerId          1.000000 -0.030183  0.005104 -0.003894  0.027698   \n",
       "Survived            -0.030183  1.000000 -0.321750 -0.059695 -0.047602   \n",
       "Pclass               0.005104 -0.321750  1.000000 -0.355950  0.086933   \n",
       "Age                 -0.003894 -0.059695 -0.355950  1.000000 -0.320916   \n",
       "SibSp                0.027698 -0.047602  0.086933 -0.320916  1.000000   \n",
       "Parch               -0.057984  0.078311  0.012679 -0.207040  0.440355   \n",
       "Fare                -0.019042  0.246641 -0.546794  0.088103  0.153011   \n",
       "AgeBucket            0.007289 -0.047526 -0.361229  0.957010 -0.305981   \n",
       "RelativesOnboard    -0.007917  0.003565  0.066748 -0.319651  0.906387   \n",
       "embarked_encoded     0.030591 -0.149680  0.124445  0.015986  0.079193   \n",
       "Richie               0.008519 -0.056505 -0.349582  0.955440 -0.303413   \n",
       "UltraRich           -0.019158  0.244957 -0.540662  0.079059  0.181026   \n",
       "sex_encoded          0.018778 -0.541750  0.128672  0.091598 -0.104174   \n",
       "UC                   0.013091 -0.521085  0.882745 -0.245294  0.022083   \n",
       "Plclass              0.023285 -0.317695  0.767058 -0.229125  0.110894   \n",
       "\n",
       "                     Parch      Fare  AgeBucket  RelativesOnboard  \\\n",
       "PassengerId      -0.057984 -0.019042   0.007289         -0.007917   \n",
       "Survived          0.078311  0.246641  -0.047526          0.003565   \n",
       "Pclass            0.012679 -0.546794  -0.361229          0.066748   \n",
       "Age              -0.207040  0.088103   0.957010         -0.319651   \n",
       "SibSp             0.440355  0.153011  -0.305981          0.906387   \n",
       "Parch             1.000000  0.222180  -0.206335          0.778416   \n",
       "Fare              0.222180  1.000000   0.089143          0.211525   \n",
       "AgeBucket        -0.206335  0.089143   1.000000         -0.309688   \n",
       "RelativesOnboard  0.778416  0.211525  -0.309688          1.000000   \n",
       "embarked_encoded  0.049868 -0.203755   0.021881          0.078835   \n",
       "Richie           -0.204779  0.075011   0.998631         -0.307185   \n",
       "UltraRich         0.245578  0.999507   0.080361          0.242122   \n",
       "sex_encoded      -0.250724 -0.171665   0.091919         -0.190809   \n",
       "UC               -0.108371 -0.530678  -0.249418         -0.035551   \n",
       "Plclass           0.040950 -0.507173  -0.229037          0.096804   \n",
       "\n",
       "                  embarked_encoded    Richie  UltraRich  sex_encoded  \\\n",
       "PassengerId               0.030591  0.008519  -0.019158     0.018778   \n",
       "Survived                 -0.149680 -0.056505   0.244957    -0.541750   \n",
       "Pclass                    0.124445 -0.349582  -0.540662     0.128672   \n",
       "Age                       0.015986  0.955440   0.079059     0.091598   \n",
       "SibSp                     0.079193 -0.303413   0.181026    -0.104174   \n",
       "Parch                     0.049868 -0.204779   0.245578    -0.250724   \n",
       "Fare                     -0.203755  0.075011   0.999507    -0.171665   \n",
       "AgeBucket                 0.021881  0.998631   0.080361     0.091919   \n",
       "RelativesOnboard          0.078835 -0.307185   0.242122    -0.190809   \n",
       "embarked_encoded          1.000000  0.074150  -0.199735     0.080068   \n",
       "Richie                    0.074150  1.000000   0.066373     0.096075   \n",
       "UltraRich                -0.199735  0.066373   1.000000    -0.176546   \n",
       "sex_encoded               0.080068  0.096075  -0.176546     1.000000   \n",
       "UC                        0.140202 -0.238039  -0.527951     0.579532   \n",
       "Plclass                   0.732046 -0.189018  -0.500364     0.140117   \n",
       "\n",
       "                        UC   Plclass  \n",
       "PassengerId       0.013091  0.023285  \n",
       "Survived         -0.521085 -0.317695  \n",
       "Pclass            0.882745  0.767058  \n",
       "Age              -0.245294 -0.229125  \n",
       "SibSp             0.022083  0.110894  \n",
       "Parch            -0.108371  0.040950  \n",
       "Fare             -0.530678 -0.507173  \n",
       "AgeBucket        -0.249418 -0.229037  \n",
       "RelativesOnboard -0.035551  0.096804  \n",
       "embarked_encoded  0.140202  0.732046  \n",
       "Richie           -0.238039 -0.189018  \n",
       "UltraRich        -0.527951 -0.500364  \n",
       "sex_encoded       0.579532  0.140117  \n",
       "UC                1.000000  0.696740  \n",
       "Plclass           0.696740  1.000000  "
      ]
     },
     "execution_count": 736,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Anecia's solutions to check the correlation \n",
    "#Survived has the highest correlation with sex_encoded, then with UC. \n",
    "trainCorr =train_data.corr()\n",
    "trainCorr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 737,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.describe();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Embarked attribute tells us where the passenger embarked: C=Cherbourg, Q=Queenstown, S=Southampton."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's build our preprocessing pipelines. We will use the `ColumnTransformer` to apply different preprocessing and feature extraction pipelines to different subsets of features. Here the numeric data is mean-imputated, while the categorical data is one-hot encoded after imputing missing values with the most frequent value in each column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 738,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 739,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data[\"UltraRich\"] = train_data[\"Fare\"] + train_data[\"RelativesOnboard\"]\n",
    "train_data[\"RichY\"] = train_data[\"Pclass\"] + train_data[\"Age\"] +train_data[\"FancyN\"]\n",
    "train_data[\"UC\"] = train_data[\"sex_encoded\"] + train_data[\"Pclass\"] \n",
    "train_data[\"AgeBucket\"] = train_data[\"Age\"] // 15 * 15\n",
    "\n",
    "\n",
    "numeric_features = [\"UltraRich\",\"RichY\",\"UC\",\"Fare\",\"AgeBucket\"] #,\"FancyN\"\n",
    "numeric_transformer = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='median'))])\n",
    "\n",
    "\n",
    "categorical_features = [\"RichS\",\"Plclass\"] \n",
    "categorical_transformer = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('onehot', OneHotEncoder(sparse=False))])\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, numeric_features),\n",
    "        ('cat', categorical_transformer, categorical_features)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cool! Now we have a nice preprocessing pipeline that takes the raw data and outputs numerical input features that we can feed to any Machine Learning model we want."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 740,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 28.5   ,  46.5   ,   2.    , ...,   1.    ,   0.    ,   0.    ],\n",
       "       [ 13.    ,  25.    ,   3.    , ...,   0.    ,   1.    ,   0.    ],\n",
       "       [  7.925 ,  35.    ,   4.    , ...,   0.    ,   0.    ,   1.    ],\n",
       "       ...,\n",
       "       [ 16.1083,  44.    ,   4.    , ...,   0.    ,   0.    ,   1.    ],\n",
       "       [123.    ,  15.    ,   1.    , ...,   1.    ,   0.    ,   0.    ],\n",
       "       [ 78.2875,  22.    ,   2.    , ...,   1.    ,   0.    ,   0.    ]])"
      ]
     },
     "execution_count": 740,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = preprocessor.fit_transform(train_data.drop(columns=[\"Survived\"]))\n",
    "X_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: We drop the \"Survived\" column from train_data before fit the preprocessor, because there is no \"Survived\" column in test_data. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's not forget to get the labels:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 741,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = train_data[\"Survived\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are now ready to train a classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 742,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 742,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "log_reg = LogisticRegression()\n",
    "log_reg.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great, our model is trained, let's use it to make predictions on the test set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 743,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"['UltraRich', 'RichY', 'UC', 'AgeBucket'] not in index\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mEmpty\u001b[0m                                     Traceback (most recent call last)",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\parallel.py:822\u001b[0m, in \u001b[0;36mParallel.dispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    821\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 822\u001b[0m     tasks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_ready_batches\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mblock\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m    823\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m queue\u001b[38;5;241m.\u001b[39mEmpty:\n\u001b[0;32m    824\u001b[0m     \u001b[38;5;66;03m# slice the iterator n_jobs * batchsize items at a time. If the\u001b[39;00m\n\u001b[0;32m    825\u001b[0m     \u001b[38;5;66;03m# slice returns less than that, then the current batchsize puts\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    828\u001b[0m     \u001b[38;5;66;03m# accordingly to distribute evenly the last items between all\u001b[39;00m\n\u001b[0;32m    829\u001b[0m     \u001b[38;5;66;03m# workers.\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\queue.py:168\u001b[0m, in \u001b[0;36mQueue.get\u001b[1;34m(self, block, timeout)\u001b[0m\n\u001b[0;32m    167\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_qsize():\n\u001b[1;32m--> 168\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m Empty\n\u001b[0;32m    169\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mEmpty\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Input \u001b[1;32mIn [743]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m#NB I have no idea why I keep getting this error since I have added these columns. I did not alter this part at all.\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m X_test \u001b[38;5;241m=\u001b[39m \u001b[43mpreprocessor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtest_data\u001b[49m\u001b[43m)\u001b[49m;\n\u001b[0;32m      3\u001b[0m y_pred\u001b[38;5;241m=\u001b[39m log_reg\u001b[38;5;241m.\u001b[39mpredict(X_test)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\compose\\_column_transformer.py:748\u001b[0m, in \u001b[0;36mColumnTransformer.transform\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    743\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    744\u001b[0m     \u001b[38;5;66;03m# ndarray was used for fitting or transforming, thus we only\u001b[39;00m\n\u001b[0;32m    745\u001b[0m     \u001b[38;5;66;03m# check that n_features_in_ is consistent\u001b[39;00m\n\u001b[0;32m    746\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_n_features(X, reset\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m--> 748\u001b[0m Xs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit_transform\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    749\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    750\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    751\u001b[0m \u001b[43m    \u001b[49m\u001b[43m_transform_one\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    752\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfitted\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    753\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcolumn_as_strings\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfit_dataframe_and_transform_dataframe\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    754\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    755\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_output(Xs)\n\u001b[0;32m    757\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m Xs:\n\u001b[0;32m    758\u001b[0m     \u001b[38;5;66;03m# All transformers are None\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\compose\\_column_transformer.py:606\u001b[0m, in \u001b[0;36mColumnTransformer._fit_transform\u001b[1;34m(self, X, y, func, fitted, column_as_strings)\u001b[0m\n\u001b[0;32m    600\u001b[0m transformers \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\n\u001b[0;32m    601\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iter(\n\u001b[0;32m    602\u001b[0m         fitted\u001b[38;5;241m=\u001b[39mfitted, replace_strings\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, column_as_strings\u001b[38;5;241m=\u001b[39mcolumn_as_strings\n\u001b[0;32m    603\u001b[0m     )\n\u001b[0;32m    604\u001b[0m )\n\u001b[0;32m    605\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 606\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mParallel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    607\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    608\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtransformer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclone\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrans\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mfitted\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtrans\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    609\u001b[0m \u001b[43m            \u001b[49m\u001b[43mX\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_safe_indexing\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    610\u001b[0m \u001b[43m            \u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    611\u001b[0m \u001b[43m            \u001b[49m\u001b[43mweight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    612\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmessage_clsname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mColumnTransformer\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    613\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmessage\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_log_message\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43midx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtransformers\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    614\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    615\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43midx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrans\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtransformers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    616\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    617\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    618\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpected 2D array, got 1D array instead\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(e):\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\parallel.py:1043\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1034\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1035\u001b[0m     \u001b[38;5;66;03m# Only set self._iterating to True if at least a batch\u001b[39;00m\n\u001b[0;32m   1036\u001b[0m     \u001b[38;5;66;03m# was dispatched. In particular this covers the edge\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1040\u001b[0m     \u001b[38;5;66;03m# was very quick and its callback already dispatched all the\u001b[39;00m\n\u001b[0;32m   1041\u001b[0m     \u001b[38;5;66;03m# remaining jobs.\u001b[39;00m\n\u001b[0;32m   1042\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iterating \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m-> 1043\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdispatch_one_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[0;32m   1044\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iterating \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_original_iterator \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1046\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdispatch_one_batch(iterator):\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\parallel.py:833\u001b[0m, in \u001b[0;36mParallel.dispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    830\u001b[0m n_jobs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_cached_effective_n_jobs\n\u001b[0;32m    831\u001b[0m big_batch_size \u001b[38;5;241m=\u001b[39m batch_size \u001b[38;5;241m*\u001b[39m n_jobs\n\u001b[1;32m--> 833\u001b[0m islice \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mitertools\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mislice\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbig_batch_size\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    834\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(islice) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m    835\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\compose\\_column_transformer.py:609\u001b[0m, in \u001b[0;36m<genexpr>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    600\u001b[0m transformers \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\n\u001b[0;32m    601\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iter(\n\u001b[0;32m    602\u001b[0m         fitted\u001b[38;5;241m=\u001b[39mfitted, replace_strings\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, column_as_strings\u001b[38;5;241m=\u001b[39mcolumn_as_strings\n\u001b[0;32m    603\u001b[0m     )\n\u001b[0;32m    604\u001b[0m )\n\u001b[0;32m    605\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    606\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m Parallel(n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_jobs)(\n\u001b[0;32m    607\u001b[0m         delayed(func)(\n\u001b[0;32m    608\u001b[0m             transformer\u001b[38;5;241m=\u001b[39mclone(trans) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m fitted \u001b[38;5;28;01melse\u001b[39;00m trans,\n\u001b[1;32m--> 609\u001b[0m             X\u001b[38;5;241m=\u001b[39m\u001b[43m_safe_indexing\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m,\n\u001b[0;32m    610\u001b[0m             y\u001b[38;5;241m=\u001b[39my,\n\u001b[0;32m    611\u001b[0m             weight\u001b[38;5;241m=\u001b[39mweight,\n\u001b[0;32m    612\u001b[0m             message_clsname\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mColumnTransformer\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    613\u001b[0m             message\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_log_message(name, idx, \u001b[38;5;28mlen\u001b[39m(transformers)),\n\u001b[0;32m    614\u001b[0m         )\n\u001b[0;32m    615\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m idx, (name, trans, column, weight) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(transformers, \u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m    616\u001b[0m     )\n\u001b[0;32m    617\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    618\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpected 2D array, got 1D array instead\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(e):\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\__init__.py:376\u001b[0m, in \u001b[0;36m_safe_indexing\u001b[1;34m(X, indices, axis)\u001b[0m\n\u001b[0;32m    370\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    371\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSpecifying the columns using strings is only supported for \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    372\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpandas DataFrames\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    373\u001b[0m     )\n\u001b[0;32m    375\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(X, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124miloc\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m--> 376\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_pandas_indexing\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindices\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindices_dtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    377\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(X, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mshape\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m    378\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _array_indexing(X, indices, indices_dtype, axis\u001b[38;5;241m=\u001b[39maxis)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\__init__.py:222\u001b[0m, in \u001b[0;36m_pandas_indexing\u001b[1;34m(X, key, key_dtype, axis)\u001b[0m\n\u001b[0;32m    219\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    220\u001b[0m     \u001b[38;5;66;03m# check whether we should index with loc or iloc\u001b[39;00m\n\u001b[0;32m    221\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m X\u001b[38;5;241m.\u001b[39miloc \u001b[38;5;28;01mif\u001b[39;00m key_dtype \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mint\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m X\u001b[38;5;241m.\u001b[39mloc\n\u001b[1;32m--> 222\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mindexer\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkey\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mif\u001b[39;00m axis \u001b[38;5;28;01melse\u001b[39;00m indexer[key]\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:961\u001b[0m, in \u001b[0;36m_LocationIndexer.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m    959\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_is_scalar_access(key):\n\u001b[0;32m    960\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj\u001b[38;5;241m.\u001b[39m_get_value(\u001b[38;5;241m*\u001b[39mkey, takeable\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_takeable)\n\u001b[1;32m--> 961\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_getitem_tuple\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    962\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    963\u001b[0m     \u001b[38;5;66;03m# we by definition only have the 0th axis\u001b[39;00m\n\u001b[0;32m    964\u001b[0m     axis \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maxis \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;241m0\u001b[39m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:1149\u001b[0m, in \u001b[0;36m_LocIndexer._getitem_tuple\u001b[1;34m(self, tup)\u001b[0m\n\u001b[0;32m   1146\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_multi_take_opportunity(tup):\n\u001b[0;32m   1147\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_multi_take(tup)\n\u001b[1;32m-> 1149\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_getitem_tuple_same_dim\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtup\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:827\u001b[0m, in \u001b[0;36m_LocationIndexer._getitem_tuple_same_dim\u001b[1;34m(self, tup)\u001b[0m\n\u001b[0;32m    824\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m com\u001b[38;5;241m.\u001b[39mis_null_slice(key):\n\u001b[0;32m    825\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[1;32m--> 827\u001b[0m retval \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mretval\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_getitem_axis\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mi\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    828\u001b[0m \u001b[38;5;66;03m# We should never have retval.ndim < self.ndim, as that should\u001b[39;00m\n\u001b[0;32m    829\u001b[0m \u001b[38;5;66;03m#  be handled by the _getitem_lowerdim call above.\u001b[39;00m\n\u001b[0;32m    830\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m retval\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mndim\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:1191\u001b[0m, in \u001b[0;36m_LocIndexer._getitem_axis\u001b[1;34m(self, key, axis)\u001b[0m\n\u001b[0;32m   1188\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(key, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mndim\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m key\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   1189\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot index with multidimensional key\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m-> 1191\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_getitem_iterable\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1193\u001b[0m \u001b[38;5;66;03m# nested tuple slicing\u001b[39;00m\n\u001b[0;32m   1194\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_nested_tuple(key, labels):\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:1132\u001b[0m, in \u001b[0;36m_LocIndexer._getitem_iterable\u001b[1;34m(self, key, axis)\u001b[0m\n\u001b[0;32m   1129\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_key(key, axis)\n\u001b[0;32m   1131\u001b[0m \u001b[38;5;66;03m# A collection of keys\u001b[39;00m\n\u001b[1;32m-> 1132\u001b[0m keyarr, indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_listlike_indexer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1133\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj\u001b[38;5;241m.\u001b[39m_reindex_with_indexers(\n\u001b[0;32m   1134\u001b[0m     {axis: [keyarr, indexer]}, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, allow_dups\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m   1135\u001b[0m )\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:1327\u001b[0m, in \u001b[0;36m_LocIndexer._get_listlike_indexer\u001b[1;34m(self, key, axis)\u001b[0m\n\u001b[0;32m   1324\u001b[0m ax \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj\u001b[38;5;241m.\u001b[39m_get_axis(axis)\n\u001b[0;32m   1325\u001b[0m axis_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj\u001b[38;5;241m.\u001b[39m_get_axis_name(axis)\n\u001b[1;32m-> 1327\u001b[0m keyarr, indexer \u001b[38;5;241m=\u001b[39m \u001b[43max\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_indexer_strict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1329\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m keyarr, indexer\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py:5782\u001b[0m, in \u001b[0;36mIndex._get_indexer_strict\u001b[1;34m(self, key, axis_name)\u001b[0m\n\u001b[0;32m   5779\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   5780\u001b[0m     keyarr, indexer, new_indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reindex_non_unique(keyarr)\n\u001b[1;32m-> 5782\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_raise_if_missing\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkeyarr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   5784\u001b[0m keyarr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtake(indexer)\n\u001b[0;32m   5785\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, Index):\n\u001b[0;32m   5786\u001b[0m     \u001b[38;5;66;03m# GH 42790 - Preserve name from an Index\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py:5845\u001b[0m, in \u001b[0;36mIndex._raise_if_missing\u001b[1;34m(self, key, indexer, axis_name)\u001b[0m\n\u001b[0;32m   5842\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNone of [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m] are in the [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00maxis_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   5844\u001b[0m not_found \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(ensure_index(key)[missing_mask\u001b[38;5;241m.\u001b[39mnonzero()[\u001b[38;5;241m0\u001b[39m]]\u001b[38;5;241m.\u001b[39munique())\n\u001b[1;32m-> 5845\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnot_found\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m not in index\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mKeyError\u001b[0m: \"['UltraRich', 'RichY', 'UC', 'AgeBucket'] not in index\""
     ]
    }
   ],
   "source": [
    "#NB I have no idea why I keep getting this error since I have added these columns. I did not alter this part at all.\n",
    "X_test = preprocessor.transform(test_data);\n",
    "y_pred= log_reg.predict(X_test);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data[\"Survived\"]=y_pred\n",
    "test_data.to_csv(\"my_solution_McMurrinBala.csv\",index=False, columns=[\"PassengerId\", \"Survived\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now we just build a CSV file with these predictions, then upload it and hope for the best. But wait! We can do better than hope. Why don't we use cross-validation to have an idea of how good our model is?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Anecia's solution\n",
    "#I changed cv to 17...\n",
    "#I did not get to 85 but I tried many different things. I also could have used cabin, lastname but for me there is no logical correlation\n",
    "#I therefore decided only to use the categories above and I have gotten to 84 so fingers crossed.\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "scores = cross_val_score(log_reg, X_train, y_train, cv=17)\n",
    "scores.mean()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Okay, over 80% accuracy, clearly better than random chance, but it's not a great score. \n",
    "\n",
    "**Your Goal**: try to build a model that reaches higher accuracy, for example, 85%."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To improve this result further, you could:\n",
    "* Tune hyperparameters using cross validation,\n",
    "* Do more feature engineering, for example:\n",
    "  * replace **SibSp** and **Parch** with their sum,\n",
    "  * try to identify parts of names that correlate well with the **Survived** attribute (e.g. if the name contains \"Countess\", then survival seems more likely),\n",
    "* try to convert numerical attributes to categorical attributes: for example, different age groups had very different survival rates (see below), so it may help to create an age bucket category and use it instead of the age. Similarly, it may be useful to have a special category for people traveling alone since only 30% of them survived (see below)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#train_data[\"AgeBucket\"] = train_data[\"Age\"] // 15 * 15\n",
    "#train_data[[\"AgeBucket\", \"Survived\"]].groupby(['AgeBucket']).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_data[\"RelativesOnboard\"] = train_data[\"SibSp\"] + train_data[\"Parch\"]\n",
    "#train_data[[\"RelativesOnboard\", \"Survived\"]].groupby(['RelativesOnboard']).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "nav_menu": {},
  "toc": {
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 6,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
